{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# In this program I get the urls of the following pdfs:\n",
        "#distributivo_personal, remuneracion_mensual, procesos_contrataciones\n",
        "\n",
        "import scrapy\n",
        "import re\n",
        "from scrapy.selector import Selector \n",
        "\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "\n",
        "class PdfDocument(scrapy.Spider):\n",
        "    name = 'hospital_documents'\n",
        "\n",
        "    # Punto de partida\n",
        "    start_urls = ['https://www.hagp.gob.ec/index.php/transparencia']\n",
        "    \n",
        "    # What we're going to do after the page is resolved\n",
        "    def parse(self, response):\n",
        "        # We yield a dict of this\n",
        "        result = {}\n",
        "        years = {\n",
        "            \"2020\": \"1\",\n",
        "            \"2019\": \"4\",\n",
        "            \"2018\": \"5\",\n",
        "            \"2017\": \"6\",\n",
        "            \"2016\": \"7\"\n",
        "        }\n",
        "\n",
        "        monthsdic = {\n",
        "            \"ENERO\": \"1\",\n",
        "            \"FEBRERO\": \"2\",\n",
        "            \"MARZO\": \"3\",\n",
        "            \"ABRIL\": \"4\",\n",
        "            \"MAYO\": \"5\",\n",
        "            \"JUNIO\": \"6\",\n",
        "            \"JULIO\": \"7\",\n",
        "            \"AGOSTO\": \"8\",\n",
        "            \"SEPTIEMBRE\": \"9\",\n",
        "            \"OCTUBRE\": \"10\",\n",
        "            \"NOVIEMBRE\": \"11\",\n",
        "            \"DICIEMBRE\": \"12\",\n",
        "        }\n",
        "\n",
        "        for index in range(2,11,2): #years (2,4,6,8,10)\n",
        "            main_xpath = \"//div[@id='lof-accordion233']/div[{0}]\".format(index)\n",
        "            # Year of the file \n",
        "            year = response.xpath(\"{0}/div/h4/text()\".format(main_xpath)).get().split()[1]\n",
        "            months = response.xpath(\"{0}/div/div[1]/div/div[1]/a/text()\".format(main_xpath)).getall()\n",
        "          \n",
        "            #result[year] = months\n",
        "            index = 0\n",
        "            while index < len(months):\n",
        "                 months[index] = re.sub('[^A-Za-z0-9]+', '', months[index])\n",
        "                 index += 1\n",
        "                             \n",
        "            \n",
        "            for month in months:\n",
        "                idfor_div = years[year] + \"-\" + monthsdic[month] + \"-\" + month.lower()\n",
        "                actual_month = month\n",
        "                #//div[@id='5-4-abril']\n",
        "                accordion_groups = \"//div[@id='\" + idfor_div + \"']\"\n",
        "                distributivo_personal = response.xpath(accordion_groups + \"//a[6]/@href\").get()\n",
        "                remuneracion_mensual = response.xpath(accordion_groups + \"//a[7]/@href\").get()\n",
        "                procesos_contrataciones = response.xpath(accordion_groups + \"//a[14]/@href\").get()\n",
        "  \n",
        "                yield {\n",
        "                            \"year\": year,\n",
        "                            \"month\": actual_month,\n",
        "                            \"distributivo_personal\": distributivo_personal,\n",
        "                            \"remuneracion_mensual\": remuneracion_mensual,\n",
        "                            \"procesos_contrataciones\": procesos_contrataciones\n",
        "                        }        \n",
        "                     \n",
        "            \n",
        "            \n",
        "         \n",
        "            \n",
        "\n",
        "#process = CrawlerProcess(settings={\n",
        "# \"FEEDS\": {r'D:\\ICD\\Proyecto\\files.json': {\"format\": \"json\"}}})\n",
        "process = CrawlerProcess(settings={\n",
        "\n",
        "    'FEED_FORMAT': \"json\",\n",
        "    'FEED_URI': \"pdfurls.json\"\n",
        "})\n",
        "process.crawl(PdfDocument)\n",
        "response = process.start()"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}